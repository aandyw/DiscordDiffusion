{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# install required packages\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "%cd diffusers\n",
        "!pip install .\n",
        "\n",
        "%cd examples/text_to_image\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# install additional packages\n",
        "!pip install accelerate wandb safetensors"
      ],
      "metadata": {
        "id": "01HiWht1rJ4j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BlNaope4sKKx",
        "outputId": "f0c1a59c-d4bb-4233-9477-f78d81727605"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/diffusers/examples/text_to_image'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup default config for accelerate\n",
        "!accelerate config default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEpbeYgzsPqx",
        "outputId": "0195b896-adf3-4b0f-eece-a05f4a8f3ab8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# login to HF and w&b\n",
        "!huggingface-cli login\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cNUg3qZsd_H",
        "outputId": "66cf71e5-3f31-4fce-cbcd-6d0ea61cfd21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LoRA SDXL"
      ],
      "metadata": {
        "id": "hfDgSNKpvLFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_text_to_image_sdxl.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
        "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
        "  --dataset_name=\"STUDs/DiscordDiffusion\" \\\n",
        "  --enable_xformers_memory_efficient_attention \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --proportion_empty_prompts=0.2 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 --gradient_checkpointing \\\n",
        "  --max_train_steps=10000 \\\n",
        "  --use_8bit_adam \\\n",
        "  --learning_rate=1e-06 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --report_to=\"wandb\" \\\n",
        "  --validation_prompt=\"shrek\" --validation_epochs 5 \\\n",
        "  --checkpointing_steps=5000 \\\n",
        "  --output_dir=\"sdxl-ddiff-model\" \\\n",
        "  --push_to_hub"
      ],
      "metadata": {
        "id": "GTTAuJonsrzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LoRA Stable Diffusion v1.5"
      ],
      "metadata": {
        "id": "0VnsoawCvQgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --dataset_name=\"STUDs/DiscordDiffusion\" \\\n",
        "  --caption_column=\"text\" \\\n",
        "  --resolution=512 --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --num_train_epochs=100 --checkpointing_steps=5000 \\\n",
        "  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --seed=42 \\\n",
        "  --output_dir=\"sd-ddiff-model-lora\" \\\n",
        "  --validation_prompt=\"shrek\" \\\n",
        "  --report_to=\"wandb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TPPcKI8va4J",
        "outputId": "f3519f4d-26cf-4b1c-b798-123d87687e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
            "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
            "2024-06-18 05:11:06.164830: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-18 05:11:06.164885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-18 05:11:06.166431: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-18 05:11:06.173889: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-18 05:11:07.352878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "06/18/2024 05:11:09 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "{'thresholding', 'sample_max_value', 'variance_type', 'dynamic_thresholding_ratio', 'prediction_type', 'timestep_spacing', 'rescale_betas_zero_snr', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'use_quant_conv', 'scaling_factor', 'shift_factor', 'force_upcast', 'latents_mean', 'use_post_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'addition_time_embed_dim', 'attention_type', 'timestep_post_act', 'time_embedding_type', 'reverse_transformer_layers_per_block', 'cross_attention_norm', 'num_attention_heads', 'use_linear_projection', 'upcast_attention', 'conv_in_kernel', 'resnet_time_scale_shift', 'num_class_embeds', 'dual_cross_attention', 'class_embed_type', 'addition_embed_type_num_heads', 'time_embedding_dim', 'encoder_hid_dim', 'resnet_skip_time_act', 'projection_class_embeddings_input_dim', 'time_embedding_act_fn', 'mid_block_only_cross_attention', 'conv_out_kernel', 'time_cond_proj_dim', 'encoder_hid_dim_type', 'transformer_layers_per_block', 'addition_embed_type', 'mid_block_type', 'resnet_out_scale_factor', 'dropout', 'class_embeddings_concat', 'only_cross_attention'} was not found in config. Values will be initialized to default values.\n",
            "Downloading readme: 100% 312/312 [00:00<00:00, 2.57MB/s]\n",
            "Downloading data: 100% 12.5M/12.5M [00:00<00:00, 21.4MB/s]\n",
            "Generating train split: 100% 54/54 [00:00<00:00, 498.42 examples/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mawu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/diffusers/examples/text_to_image/wandb/run-20240618_051120-gx9j49ty\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdifferent-rain-22\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/awu/text2image-fine-tune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/awu/text2image-fine-tune/runs/gx9j49ty\u001b[0m\n",
            "06/18/2024 05:11:21 - INFO - __main__ - ***** Running training *****\n",
            "06/18/2024 05:11:21 - INFO - __main__ -   Num examples = 54\n",
            "06/18/2024 05:11:21 - INFO - __main__ -   Num Epochs = 100\n",
            "06/18/2024 05:11:21 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "06/18/2024 05:11:21 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "06/18/2024 05:11:21 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "06/18/2024 05:11:21 - INFO - __main__ -   Total optimization steps = 5400\n",
            "Steps:   1% 54/5400 [00:22<32:43,  2.72it/s, lr=0.0001, step_loss=0.166]  \n",
            "model_index.json: 100% 541/541 [00:00<00:00, 2.13MB/s]\n",
            "\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "(…)ature_extractor/preprocessor_config.json: 100% 342/342 [00:00<00:00, 1.22MB/s]\n",
            "\n",
            "Fetching 13 files:   8% 1/13 [00:00<00:02,  5.70it/s]\u001b[A\n",
            "\n",
            "safety_checker/config.json: 100% 4.72k/4.72k [00:00<00:00, 14.4MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   1% 10.5M/1.22G [00:00<00:20, 59.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   3% 31.5M/1.22G [00:00<00:09, 119MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   4% 52.4M/1.22G [00:00<00:08, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   6% 73.4M/1.22G [00:00<00:07, 163MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   8% 94.4M/1.22G [00:00<00:06, 173MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   9% 115M/1.22G [00:00<00:06, 171MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  11% 136M/1.22G [00:00<00:06, 165MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  13% 157M/1.22G [00:01<00:06, 167MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  15% 178M/1.22G [00:01<00:06, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  16% 199M/1.22G [00:01<00:05, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  18% 220M/1.22G [00:01<00:05, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  20% 241M/1.22G [00:01<00:05, 178MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  22% 262M/1.22G [00:01<00:05, 177MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  23% 283M/1.22G [00:01<00:05, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  25% 304M/1.22G [00:01<00:04, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  27% 325M/1.22G [00:01<00:04, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  28% 346M/1.22G [00:02<00:04, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  30% 367M/1.22G [00:02<00:04, 178MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  32% 388M/1.22G [00:02<00:04, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  34% 409M/1.22G [00:02<00:04, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  35% 430M/1.22G [00:02<00:04, 189MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  37% 451M/1.22G [00:02<00:04, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  39% 472M/1.22G [00:02<00:04, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  41% 493M/1.22G [00:02<00:04, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  42% 514M/1.22G [00:02<00:04, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  44% 535M/1.22G [00:03<00:03, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  46% 556M/1.22G [00:03<00:03, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  47% 577M/1.22G [00:03<00:03, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  49% 598M/1.22G [00:03<00:03, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  51% 619M/1.22G [00:03<00:03, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  53% 640M/1.22G [00:03<00:03, 177MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  54% 661M/1.22G [00:03<00:03, 178MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  56% 682M/1.22G [00:03<00:02, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  58% 703M/1.22G [00:03<00:02, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  60% 724M/1.22G [00:04<00:02, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  61% 744M/1.22G [00:04<00:02, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  63% 765M/1.22G [00:04<00:02, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  65% 786M/1.22G [00:04<00:02, 173MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  66% 807M/1.22G [00:04<00:02, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  68% 828M/1.22G [00:04<00:02, 170MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  70% 849M/1.22G [00:04<00:02, 171MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  72% 870M/1.22G [00:07<00:14, 23.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  73% 891M/1.22G [00:07<00:10, 31.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  75% 912M/1.22G [00:07<00:07, 42.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  77% 933M/1.22G [00:07<00:05, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  78% 954M/1.22G [00:07<00:03, 70.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  80% 975M/1.22G [00:08<00:02, 83.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  82% 996M/1.22G [00:08<00:02, 96.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  84% 1.02G/1.22G [00:08<00:01, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  85% 1.04G/1.22G [00:08<00:01, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  87% 1.06G/1.22G [00:08<00:01, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  89% 1.08G/1.22G [00:08<00:00, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  91% 1.10G/1.22G [00:08<00:00, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  92% 1.12G/1.22G [00:09<00:00, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  94% 1.14G/1.22G [00:09<00:00, 151MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  96% 1.16G/1.22G [00:09<00:00, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  97% 1.18G/1.22G [00:09<00:00, 162MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors: 100% 1.22G/1.22G [00:09<00:00, 125MB/s]\n",
            "\n",
            "Fetching 13 files: 100% 13/13 [00:09<00:00,  1.31it/s]\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.26it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'use_quant_conv', 'scaling_factor', 'shift_factor', 'force_upcast', 'latents_mean', 'use_post_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:01<00:01,  2.24it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  71% 5/7 [00:02<00:01,  1.65it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.35it/s]\n",
            "06/18/2024 05:11:57 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: shrek.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:   2% 108/5400 [01:21<34:19,  2.57it/s, lr=0.0001, step_loss=0.00737]{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:02,  2.25it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'use_quant_conv', 'scaling_factor', 'shift_factor', 'force_upcast', 'latents_mean', 'use_post_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  8.35it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:01<00:00,  3.97it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  4.91it/s]\n",
            "06/18/2024 05:12:44 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: shrek.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:   3% 162/5400 [02:11<35:21,  2.47it/s, lr=0.0001, step_loss=0.185]{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:02,  2.30it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'use_quant_conv', 'scaling_factor', 'shift_factor', 'force_upcast', 'latents_mean', 'use_post_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  8.61it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:01<00:00,  4.25it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  5.21it/s]\n",
            "06/18/2024 05:13:33 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: shrek.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:   4% 216/5400 [03:00<34:51,  2.48it/s, lr=0.0001, step_loss=0.133]  {'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:02,  2.14it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'use_quant_conv', 'scaling_factor', 'shift_factor', 'force_upcast', 'latents_mean', 'use_post_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  7.97it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:01<00:00,  4.06it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  4.95it/s]\n",
            "06/18/2024 05:14:23 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: shrek.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:   5% 270/5400 [03:49<34:15,  2.50it/s, lr=0.0001, step_loss=0.168]{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:03,  1.75it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'use_quant_conv', 'scaling_factor', 'shift_factor', 'force_upcast', 'latents_mean', 'use_post_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  6.41it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:01<00:00,  3.14it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  3.86it/s]\n",
            "06/18/2024 05:15:12 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: shrek.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:   6% 324/5400 [04:39<33:34,  2.52it/s, lr=0.0001, step_loss=0.0738]{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:02,  2.29it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'use_quant_conv', 'scaling_factor', 'shift_factor', 'force_upcast', 'latents_mean', 'use_post_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  8.42it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:01<00:00,  4.16it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  5.11it/s]\n",
            "06/18/2024 05:16:02 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: shrek.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOfvH22YwWO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}