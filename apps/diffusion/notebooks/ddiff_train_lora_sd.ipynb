{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0VnsoawCvQgw"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# install required packages\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "%cd diffusers\n",
        "!pip install .\n",
        "\n",
        "%cd examples/text_to_image\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# install additional packages\n",
        "!pip install accelerate wandb safetensors"
      ],
      "metadata": {
        "id": "01HiWht1rJ4j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BlNaope4sKKx",
        "outputId": "f0c1a59c-d4bb-4233-9477-f78d81727605"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/diffusers/examples/text_to_image'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup default config for accelerate\n",
        "!accelerate config default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEpbeYgzsPqx",
        "outputId": "0195b896-adf3-4b0f-eece-a05f4a8f3ab8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# login to HF and w&b\n",
        "!huggingface-cli login\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cNUg3qZsd_H",
        "outputId": "66cf71e5-3f31-4fce-cbcd-6d0ea61cfd21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LoRA Stable Diffusion v1.5"
      ],
      "metadata": {
        "id": "0VnsoawCvQgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of LoRA fine-tuning with Stable Diffusion v1.5 is not the greatest. We should focus our efforts on fine-tuning SDXL instead which already has an inherent understanding of the desired sticker generations."
      ],
      "metadata": {
        "id": "UN03ktV4yRU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !accelerate launch train_text_to_image_lora.py \\\n",
        "#   --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "#   --dataset_name=\"STUDs/DiscordDiffusion\" \\\n",
        "#   --caption_column=\"text\" \\\n",
        "#   --resolution=512 --random_flip \\\n",
        "#   --train_batch_size=1 \\\n",
        "#   --num_train_epochs=100 --checkpointing_steps=5000 \\\n",
        "#   --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "#   --mixed_precision=\"fp16\" \\\n",
        "#   --seed=42 \\\n",
        "#   --output_dir=\"sd-ddiff-model-lora\" \\\n",
        "#   --validation_prompt=\"shrek\" \\\n",
        "#   --report_to=\"wandb\""
      ],
      "metadata": {
        "id": "1TPPcKI8va4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LoRA SDXL"
      ],
      "metadata": {
        "id": "hfDgSNKpvLFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_text_to_image_sdxl.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
        "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
        "  --dataset_name=\"STUDs/DiscordDiffusion\" \\\n",
        "  --enable_xformers_memory_efficient_attention \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --proportion_empty_prompts=0.2 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 --gradient_checkpointing \\\n",
        "  --max_train_steps=10000 \\\n",
        "  --use_8bit_adam \\\n",
        "  --learning_rate=1e-06 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --report_to=\"wandb\" \\\n",
        "  --validation_prompt=\"shrek\" --validation_epochs 5 \\\n",
        "  --checkpointing_steps=5000 \\\n",
        "  --output_dir=\"sdxl-ddiff-model\" \\\n",
        "  --push_to_hub"
      ],
      "metadata": {
        "id": "GTTAuJonsrzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}